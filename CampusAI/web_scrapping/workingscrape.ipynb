{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv\n",
    "\n",
    "\n",
    "class BrowserTab:\n",
    "    def __init__(self, driver, handle):\n",
    "        self.driver = driver\n",
    "        self.handle = handle\n",
    "\n",
    "    def openUrl(self, url):\n",
    "        # Switch to this tab before performing actions on it\n",
    "        self.driver.switch_to.window(self.handle)\n",
    "        self.driver.get(url)\n",
    "\n",
    "    def closeTab(self):\n",
    "        # Switch to this tab before closing it\n",
    "        self.driver.switch_to.window(self.handle)\n",
    "        self.driver.close()\n",
    "\n",
    "    def getTitle(self):\n",
    "        # Switch to this tab before getting the title\n",
    "        self.driver.switch_to.window(self.handle)\n",
    "        return self.driver.title\n",
    "\n",
    "    def clickElementWithId(self, text):\n",
    "        element = self.driver.find_element(By.ID, text)\n",
    "        element.click()\n",
    "        return\n",
    "\n",
    "    def clickSpecificElementWithClass(self, element_type, class_name):\n",
    "        # Construct the XPath based on the element type and class name\n",
    "        xpath = f\"//{element_type}[@class='{class_name}']\"\n",
    "\n",
    "        # Find the element\n",
    "        element = self.driver.find_element(By.XPATH, xpath)\n",
    "\n",
    "        # Click on the element\n",
    "        element.click()\n",
    "\n",
    "    def clickSpecificElementWithName(self, element_type, name):\n",
    "        # Construct the XPath based on the element type and name attribute\n",
    "        xpath = f\"//{element_type}[@name='{name}']\"\n",
    "\n",
    "        # Find the element\n",
    "        element = self.driver.find_element(By.XPATH, xpath)\n",
    "\n",
    "        # Click on the element\n",
    "        element.click()\n",
    "\n",
    "    def clickSpecificElementWithText(self, element_type, name):\n",
    "        # Construct the XPath based on the element type and name attribute\n",
    "        xpath = f\"//{element_type}[contains(text(),'{name}')]\"\n",
    "\n",
    "        # Find the element\n",
    "        element = self.driver.find_element(By.XPATH, xpath)\n",
    "\n",
    "        # Click on the element\n",
    "        element.click()\n",
    "\n",
    "\n",
    "    def clickElementWithText(self, text):\n",
    "        element = self.driver.find_element(By.XPATH, f\"//*[contains(text(), '{text}')]\")\n",
    "        element.click()\n",
    "        return\n",
    "\n",
    "    def waitUntilLoaded(self):\n",
    "        while self.driver.execute_script(\"return document.readyState\") != \"complete\":\n",
    "            time.sleep(0.1)\n",
    "        return\n",
    "\n",
    "    def clickLinkWithText(self, text):\n",
    "        element = self.driver.find_element(By.XPATH, f\"//a[contains(text(), '{text}')]\")\n",
    "        element.click()\n",
    "        return\n",
    "\n",
    "    def clickElementWithClass(self, text):\n",
    "        element = self.driver.find_element(By.CLASS_NAME, text)\n",
    "        element.click()\n",
    "        return\n",
    "\n",
    "    def getTextFromInput(self, text):\n",
    "        return self.driver.find_element(By.ID, text).get_attribute(\"value\")\n",
    "\n",
    "    def findImages(self):\n",
    "        soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "        images = soup.find_all(\"img\", src=lambda value: value and \".jpg\" in value)\n",
    "        return images\n",
    "\n",
    "    def getElementWithId(self, id):\n",
    "        element = self.driver.find_element(By.ID, id)\n",
    "        return element\n",
    "\n",
    "    def getElementWithName(self, id):\n",
    "        element = self.driver.find_element(By.NAME, id)\n",
    "        return element\n",
    "\n",
    "    def getElementWithClass(self, id):\n",
    "        element = self.driver.find_element(By.CLASS_NAME, id)\n",
    "        return element\n",
    "\n",
    "\n",
    "class BrowserManager:\n",
    "    def __init__(self):\n",
    "        self.driver = webdriver.Chrome()\n",
    "        self.tabs = []\n",
    "\n",
    "    def openNewTab(self):\n",
    "        # Open a new tab and add its handle to the list of tabs\n",
    "        self.driver.execute_script(\"window.open('');\")\n",
    "        new_handle = self.driver.window_handles[-1]\n",
    "        tab = BrowserTab(self.driver, new_handle)\n",
    "        self.tabs.append(tab)\n",
    "        return tab\n",
    "\n",
    "    def closeBrowser(self):\n",
    "        # Close the entire browser\n",
    "        self.driver.quit()\n",
    "\n",
    "    def switchToTab(self, index):\n",
    "        # Switch to the tab based on the given index\n",
    "        handle = self.driver.window_handles[index]\n",
    "        self.driver.switch_to.window(handle)\n",
    "\n",
    "    def refreshTab(self):\n",
    "        self.refreshTab()\n",
    "        return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "browserManager = BrowserManager()\n",
    "stock=\"ntc\"\n",
    "            # Open a new tab\n",
    "tab1 = browserManager.openNewTab()\n",
    "tab1.openUrl(f'https://www.sharesansar.com/company/{stock}')\n",
    "time.sleep(10)\n",
    "tab1.clickElementWithId(\"btn_cpricehistory\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab1.clickSpecificElementWithName(\"select\",\"myTableCPriceHistory_length\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab1.clickSpecificElementWithName(\"select\",\"myTableCPriceHistory_length\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab1.clickSpecificElementWithText(\"option\", \"50\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## New  without header problem\n",
    "import csv\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "for i in range(1):\n",
    "    page_source=tab1.driver.page_source\n",
    "    \n",
    "    #Parse the page source with BeautifulSoup\n",
    "    soup=BeautifulSoup(page_source, \"html.parser\")\n",
    "    \n",
    "    # Find the table with id 'myTableCPriceHistory'\n",
    "    table = soup.find(\"table\", {\"id\": \"myTableCPriceHistory\"})\n",
    "    \n",
    "    if table:\n",
    "        rows=table.find_all(\"tr\")\n",
    "        table_data=[]\n",
    "        \n",
    "        for row in rows:\n",
    "            cols = row.find_all([\"th\"])  # Fix incorrect syntax\n",
    "            cols = [ele.text.strip() for ele in cols if ele.text.strip()]  # Remove empty elements\n",
    "            if cols:  # Only add non-empty rows\n",
    "                table_data.append(cols)\n",
    "                \n",
    "            # Append the data to a CSV file\n",
    "        if table_data:  # Ensure data is not empty before writing\n",
    "            # stock=\"ntc\"\n",
    "            with open(f\"{stock}.csv\", \"a\", newline=\"\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerows(table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0, 56):\n",
    "#             page_source = tab1.driver.page_source\n",
    "\n",
    "#             # Parse the page source with BeautifulSoup\n",
    "#             soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "#             # Find the table with id 'myTableCPriceHistory'\n",
    "#             table = soup.find(\"table\", {\"id\": \"myTableCPriceHistory\"})\n",
    "#             if table:\n",
    "#                 # Extract the table data\n",
    "#                 rows = table.find_all(\"tr\")\n",
    "#                 table_data = []\n",
    "#                 for row in rows:\n",
    "#                     cols = row.find_all(\"td\")\n",
    "#                     cols = [ele.text.strip() for ele in cols]\n",
    "#                     table_data.append([ele for ele in cols if ele])\n",
    "#                 # Append the data to a CSV file\n",
    "#                 with open(\"table_data.csv\", \"a\", newline=\"\") as f:\n",
    "#                     writer = csv.writer(f)\n",
    "#                     writer.writerows(table_data)\n",
    "#             else:\n",
    "#                 print(f\"Table not found on page {i}\")\n",
    "#             tab1.clickElementWithId(\"myTableCPriceHistory_next\")    \n",
    "#             time.sleep(2)\n",
    "            \n",
    "\n",
    "\n",
    "for i in range(0, 5):\n",
    "    page_source = tab1.driver.page_source\n",
    "\n",
    "    # Parse the page source with BeautifulSoup\n",
    "    soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "    \n",
    "    # Find the table with id 'myTableCPriceHistory'\n",
    "    table = soup.find(\"table\", {\"id\": \"myTableCPriceHistory\"})\n",
    "    if table:\n",
    "        # Extract the table data\n",
    "        rows = table.find_all(\"tr\")\n",
    "        table_data = []\n",
    "        # header=True\n",
    "        \n",
    "        # for adding of the row also \n",
    "        \n",
    "        # for row in rows:\n",
    "        #     cols = row.find_all([\"td\", \"th\"])  # Fix incorrect syntax\n",
    "        #     cols = [ele.text.strip() for ele in cols if ele.text.strip()]  # Remove empty elements\n",
    "        #     if cols:  # Only add non-empty rows\n",
    "        #         table_data.append(cols)\n",
    "                \n",
    "        #     # Append the data to a CSV file\n",
    "        #     if table_data:  # Ensure data is not empty before writing\n",
    "        #         with open(f\"{stock}.csv\", \"a\", newline=\"\") as f:\n",
    "        #             writer = csv.writer(f)\n",
    "        #             writer.writerows(table_data)\n",
    "        \n",
    "        # for index, row in enumerate(rows):\n",
    "        for  index,row in enumerate(rows):\n",
    "            if index == 0:  # Skip the first row (header row)\n",
    "                continue\n",
    "\n",
    "            cols = row.find_all([\"td\", \"th\"])  # Fix incorrect syntax\n",
    "            cols = [ele.text.strip() for ele in cols if ele.text.strip()]  # Remove empty elements\n",
    "            if cols:  # Only add non-empty rows\n",
    "                table_data.append(cols)\n",
    "        \n",
    "        # Append the data to a CSV file\n",
    "        if table_data:  # Ensure data is not empty before writing\n",
    "            with open(f\"{stock}.csv\", \"a\", newline=\"\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerows(table_data)\n",
    "    else:\n",
    "        print(f\"Table not found on page {i}\")\n",
    "    try:\n",
    "        tab1.clickElementWithId(\"myTableCPriceHistory_next\")    \n",
    "        time.sleep(2)\n",
    "    except Exception as e:\n",
    "        print(f\"Error clicking next button on page {i}: {e}\")\n",
    "    \n",
    "   \n",
    "# import csv\n",
    "# import time\n",
    "# import os\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# csv_filename = \"table_data.csv\"\n",
    "\n",
    "# for i in range(5):  # Loop through 5 pages\n",
    "#     page_source = tab1.driver.page_source\n",
    "\n",
    "#     # Parse the page source with BeautifulSoup\n",
    "#     soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "#     # Find the table with id 'myTableCPriceHistory'\n",
    "#     table = soup.find(\"table\", {\"id\": \"myTableCPriceHistory\"})\n",
    "#     if table:\n",
    "#         rows = table.find_all(\"tr\")\n",
    "#         table_data = []\n",
    "\n",
    "#         for row in rows:\n",
    "#             cols = row.find_all([\"td\", \"th\"])  # Corrected the `||` issue\n",
    "#             cols = [ele.text.strip() for ele in cols if ele.text.strip()]  # Remove empty elements\n",
    "#             if cols:\n",
    "#                 table_data.append(cols)\n",
    "\n",
    "#         # Check if file exists to write the header only once\n",
    "#         write_header = not os.path.exists(csv_filename)\n",
    "\n",
    "#         # Append the data to a CSV file\n",
    "#         if table_data:\n",
    "#             with open(csv_filename, \"a\", newline=\"\") as f:\n",
    "#                 writer = csv.writer(f)\n",
    "#                 if write_header:  # Write headers only if the file is new\n",
    "#                     writer.writerow(table_data[0])  # First row as headers\n",
    "#                 writer.writerows(table_data[1:])  # Write remaining data\n",
    "#     else:\n",
    "#         print(f\"Table not found on page {i}\")\n",
    "\n",
    "    # Click the next page button\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     # Click the next page button\n",
    "# try:\n",
    "#    tab1.clickElementWithId(\"myTableCPriceHistory_next\")\n",
    "#    time.sleep(2)  # Wait for the page to load\n",
    "# except Exception as e:\n",
    "#    print(f\"Error clicking next button on page {i}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the reversing of the data\n",
    "import pandas as pd\n",
    "# stock=\"ntc\"\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(f'{stock}.csv')\n",
    "\n",
    "# Reverse the order of rows\n",
    "df = df[::-1]\n",
    "\n",
    "# print(\"Before Reversing:\")\n",
    "# print(df.head())  # Check the first few rows\n",
    "\n",
    "# df = df[::-1]  # Reverse\n",
    "\n",
    "# print(\"After Reversing:\")\n",
    "# print(df.head())  # Check again\n",
    "\n",
    "\n",
    "# Save the modified CSV\n",
    "# df.to_csv(f\"sorted_{stock}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.N.</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Ltp</th>\n",
       "      <th>% Change</th>\n",
       "      <th>Qty</th>\n",
       "      <th>Turnover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>2024-09-10</td>\n",
       "      <td>980.00</td>\n",
       "      <td>999.60</td>\n",
       "      <td>968.3</td>\n",
       "      <td>975.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>59,563.00</td>\n",
       "      <td>58,265,989.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>2024-09-11</td>\n",
       "      <td>975.10</td>\n",
       "      <td>992.00</td>\n",
       "      <td>963.0</td>\n",
       "      <td>965.00</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>32,622.00</td>\n",
       "      <td>31,758,932.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>2024-09-12</td>\n",
       "      <td>984.30</td>\n",
       "      <td>987.00</td>\n",
       "      <td>960.1</td>\n",
       "      <td>985.00</td>\n",
       "      <td>2.07</td>\n",
       "      <td>27,804.00</td>\n",
       "      <td>27,129,890.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>2024-09-15</td>\n",
       "      <td>986.00</td>\n",
       "      <td>995.00</td>\n",
       "      <td>966.4</td>\n",
       "      <td>967.00</td>\n",
       "      <td>-1.83</td>\n",
       "      <td>52,289.00</td>\n",
       "      <td>51,201,716.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>2024-09-16</td>\n",
       "      <td>980.00</td>\n",
       "      <td>980.00</td>\n",
       "      <td>941.0</td>\n",
       "      <td>946.90</td>\n",
       "      <td>-2.08</td>\n",
       "      <td>38,521.00</td>\n",
       "      <td>36,656,246.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2025-02-13</td>\n",
       "      <td>881.00</td>\n",
       "      <td>885.00</td>\n",
       "      <td>878.1</td>\n",
       "      <td>880.00</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>16,608.00</td>\n",
       "      <td>14,623,922.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2025-02-16</td>\n",
       "      <td>890.00</td>\n",
       "      <td>890.00</td>\n",
       "      <td>880.2</td>\n",
       "      <td>885.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>12,892.00</td>\n",
       "      <td>11,391,593.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-02-17</td>\n",
       "      <td>898.90</td>\n",
       "      <td>901.00</td>\n",
       "      <td>885.0</td>\n",
       "      <td>897.00</td>\n",
       "      <td>1.36</td>\n",
       "      <td>18,497.00</td>\n",
       "      <td>16,546,112.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-02-18</td>\n",
       "      <td>902.00</td>\n",
       "      <td>911.90</td>\n",
       "      <td>895.1</td>\n",
       "      <td>910.00</td>\n",
       "      <td>1.45</td>\n",
       "      <td>30,997.00</td>\n",
       "      <td>28,087,993.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-02-20</td>\n",
       "      <td>910.00</td>\n",
       "      <td>921.00</td>\n",
       "      <td>908.0</td>\n",
       "      <td>910.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25,513.00</td>\n",
       "      <td>23,323,952.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    S.N.        Date    Open    High    Low     Ltp  % Change        Qty  \\\n",
       "99   100  2024-09-10  980.00  999.60  968.3  975.00      0.83  59,563.00   \n",
       "98    99  2024-09-11  975.10  992.00  963.0  965.00     -1.03  32,622.00   \n",
       "97    98  2024-09-12  984.30  987.00  960.1  985.00      2.07  27,804.00   \n",
       "96    97  2024-09-15  986.00  995.00  966.4  967.00     -1.83  52,289.00   \n",
       "95    96  2024-09-16  980.00  980.00  941.0  946.90     -2.08  38,521.00   \n",
       "..   ...         ...     ...     ...    ...     ...       ...        ...   \n",
       "4      5  2025-02-13  881.00  885.00  878.1  880.00     -0.11  16,608.00   \n",
       "3      4  2025-02-16  890.00  890.00  880.2  885.00      0.57  12,892.00   \n",
       "2      3  2025-02-17  898.90  901.00  885.0  897.00      1.36  18,497.00   \n",
       "1      2  2025-02-18  902.00  911.90  895.1  910.00      1.45  30,997.00   \n",
       "0      1  2025-02-20  910.00  921.00  908.0  910.00      0.00  25,513.00   \n",
       "\n",
       "         Turnover  \n",
       "99  58,265,989.20  \n",
       "98  31,758,932.60  \n",
       "97  27,129,890.50  \n",
       "96  51,201,716.80  \n",
       "95  36,656,246.20  \n",
       "..            ...  \n",
       "4   14,623,922.90  \n",
       "3   11,391,593.30  \n",
       "2   16,546,112.20  \n",
       "1   28,087,993.80  \n",
       "0   23,323,952.60  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# # Remove commas from specific column (e.g., 'Price')\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpen\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOpen\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m      3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHigh\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHigh\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m      4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLow\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLow\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/tfEnv/lib/python3.8/site-packages/pandas/core/generic.py:5989\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5983\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5984\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5985\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5986\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5987\u001b[0m ):\n\u001b[1;32m   5988\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5989\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/tfEnv/lib/python3.8/site-packages/pandas/core/accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[0;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/tfEnv/lib/python3.8/site-packages/pandas/core/strings/accessor.py:181\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m is_categorical_dtype(data\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/tfEnv/lib/python3.8/site-packages/pandas/core/strings/accessor.py:235\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    232\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[0;32m--> 235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "# # Remove commas from specific column (e.g., 'Price')\n",
    "df['Open'] = df['Open'].str.replace(',', '').astype(float)\n",
    "df['High'] = df['High'].str.replace(',', '').astype(float)\n",
    "df['Low'] = df['Low'].str.replace(',', '').astype(float)\n",
    "df['Ltp'] = df['Ltp'].str.replace(',', '').astype(float)\n",
    "df['Qty'] = df['Qty'].str.replace(',', '').astype(float)\n",
    "df['Turnover'] = df['Turnover'].str.replace(',', '').astype(float)\n",
    "\n",
    "df.to_csv(f\"sorted_{stock}.csv\", index=False)\n",
    "\n",
    "# # Save cleaned data back to CSV\n",
    "# df.to_csv(\"cleaned_file.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
