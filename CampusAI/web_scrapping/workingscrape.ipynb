{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv\n",
    "\n",
    "\n",
    "class BrowserTab:\n",
    "    def __init__(self, driver, handle):\n",
    "        self.driver = driver\n",
    "        self.handle = handle\n",
    "\n",
    "    def openUrl(self, url):\n",
    "        # Switch to this tab before performing actions on it\n",
    "        self.driver.switch_to.window(self.handle)\n",
    "        self.driver.get(url)\n",
    "\n",
    "    def closeTab(self):\n",
    "        # Switch to this tab before closing it\n",
    "        self.driver.switch_to.window(self.handle)\n",
    "        self.driver.close()\n",
    "\n",
    "    def getTitle(self):\n",
    "        # Switch to this tab before getting the title\n",
    "        self.driver.switch_to.window(self.handle)\n",
    "        return self.driver.title\n",
    "\n",
    "    def clickElementWithId(self, text):\n",
    "        element = self.driver.find_element(By.ID, text)\n",
    "        element.click()\n",
    "        return\n",
    "\n",
    "    def clickSpecificElementWithClass(self, element_type, class_name):\n",
    "        # Construct the XPath based on the element type and class name\n",
    "        xpath = f\"//{element_type}[@class='{class_name}']\"\n",
    "\n",
    "        # Find the element\n",
    "        element = self.driver.find_element(By.XPATH, xpath)\n",
    "\n",
    "        # Click on the element\n",
    "        element.click()\n",
    "\n",
    "    def clickSpecificElementWithName(self, element_type, name):\n",
    "        # Construct the XPath based on the element type and name attribute\n",
    "        xpath = f\"//{element_type}[@name='{name}']\"\n",
    "\n",
    "        # Find the element\n",
    "        element = self.driver.find_element(By.XPATH, xpath)\n",
    "\n",
    "        # Click on the element\n",
    "        element.click()\n",
    "\n",
    "    def clickSpecificElementWithText(self, element_type, name):\n",
    "        # Construct the XPath based on the element type and name attribute\n",
    "        xpath = f\"//{element_type}[contains(text(),'{name}')]\"\n",
    "\n",
    "        # Find the element\n",
    "        element = self.driver.find_element(By.XPATH, xpath)\n",
    "\n",
    "        # Click on the element\n",
    "        element.click()\n",
    "\n",
    "\n",
    "    def clickElementWithText(self, text):\n",
    "        element = self.driver.find_element(By.XPATH, f\"//*[contains(text(), '{text}')]\")\n",
    "        element.click()\n",
    "        return\n",
    "\n",
    "    def waitUntilLoaded(self):\n",
    "        while self.driver.execute_script(\"return document.readyState\") != \"complete\":\n",
    "            time.sleep(0.1)\n",
    "        return\n",
    "\n",
    "    def clickLinkWithText(self, text):\n",
    "        element = self.driver.find_element(By.XPATH, f\"//a[contains(text(), '{text}')]\")\n",
    "        element.click()\n",
    "        return\n",
    "\n",
    "    def clickElementWithClass(self, text):\n",
    "        element = self.driver.find_element(By.CLASS_NAME, text)\n",
    "        element.click()\n",
    "        return\n",
    "\n",
    "    def getTextFromInput(self, text):\n",
    "        return self.driver.find_element(By.ID, text).get_attribute(\"value\")\n",
    "\n",
    "    def findImages(self):\n",
    "        soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "        images = soup.find_all(\"img\", src=lambda value: value and \".jpg\" in value)\n",
    "        return images\n",
    "\n",
    "    def getElementWithId(self, id):\n",
    "        element = self.driver.find_element(By.ID, id)\n",
    "        return element\n",
    "\n",
    "    def getElementWithName(self, id):\n",
    "        element = self.driver.find_element(By.NAME, id)\n",
    "        return element\n",
    "\n",
    "    def getElementWithClass(self, id):\n",
    "        element = self.driver.find_element(By.CLASS_NAME, id)\n",
    "        return element\n",
    "\n",
    "\n",
    "class BrowserManager:\n",
    "    def __init__(self):\n",
    "        self.driver = webdriver.Chrome()\n",
    "        self.tabs = []\n",
    "\n",
    "    def openNewTab(self):\n",
    "        # Open a new tab and add its handle to the list of tabs\n",
    "        self.driver.execute_script(\"window.open('');\")\n",
    "        new_handle = self.driver.window_handles[-1]\n",
    "        tab = BrowserTab(self.driver, new_handle)\n",
    "        self.tabs.append(tab)\n",
    "        return tab\n",
    "\n",
    "    def closeBrowser(self):\n",
    "        # Close the entire browser\n",
    "        self.driver.quit()\n",
    "\n",
    "    def switchToTab(self, index):\n",
    "        # Switch to the tab based on the given index\n",
    "        handle = self.driver.window_handles[index]\n",
    "        self.driver.switch_to.window(handle)\n",
    "\n",
    "    def refreshTab(self):\n",
    "        self.refreshTab()\n",
    "        return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "browserManager = BrowserManager()\n",
    "stock=\"kbl\"\n",
    "            # Open a new tab\n",
    "tab1 = browserManager.openNewTab()\n",
    "tab1.openUrl(f'https://www.sharesansar.com/company/{stock}')\n",
    "time.sleep(1)\n",
    "tab1.clickElementWithId(\"btn_cpricehistory\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab1.clickSpecificElementWithName(\"select\",\"myTableCPriceHistory_length\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab1.clickSpecificElementWithName(\"select\",\"myTableCPriceHistory_length\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab1.clickSpecificElementWithText(\"option\", \"50\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0, 56):\n",
    "#             page_source = tab1.driver.page_source\n",
    "\n",
    "#             # Parse the page source with BeautifulSoup\n",
    "#             soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "#             # Find the table with id 'myTableCPriceHistory'\n",
    "#             table = soup.find(\"table\", {\"id\": \"myTableCPriceHistory\"})\n",
    "#             if table:\n",
    "#                 # Extract the table data\n",
    "#                 rows = table.find_all(\"tr\")\n",
    "#                 table_data = []\n",
    "#                 for row in rows:\n",
    "#                     cols = row.find_all(\"td\")\n",
    "#                     cols = [ele.text.strip() for ele in cols]\n",
    "#                     table_data.append([ele for ele in cols if ele])\n",
    "#                 # Append the data to a CSV file\n",
    "#                 with open(\"table_data.csv\", \"a\", newline=\"\") as f:\n",
    "#                     writer = csv.writer(f)\n",
    "#                     writer.writerows(table_data)\n",
    "#             else:\n",
    "#                 print(f\"Table not found on page {i}\")\n",
    "#             tab1.clickElementWithId(\"myTableCPriceHistory_next\")    \n",
    "#             time.sleep(2)\n",
    "            \n",
    "## New  without header problem\n",
    "import csv\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "for i in range(0, 5):\n",
    "    page_source = tab1.driver.page_source\n",
    "\n",
    "    # Parse the page source with BeautifulSoup\n",
    "    soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "    \n",
    "    # Find the table with id 'myTableCPriceHistory'\n",
    "    table = soup.find(\"table\", {\"id\": \"myTableCPriceHistory\"})\n",
    "    if table:\n",
    "        # Extract the table data\n",
    "        rows = table.find_all(\"tr\")\n",
    "        table_data = []\n",
    "        \n",
    "        for index, row in enumerate(rows):\n",
    "            if index == 0:  # Skip the first row (header row)\n",
    "                continue\n",
    "\n",
    "            cols = row.find_all(\"td\")\n",
    "            cols = [ele.text.strip() for ele in cols if ele.text.strip()]  # Remove empty elements\n",
    "            if cols:  # Only add non-empty rows\n",
    "                table_data.append(cols)\n",
    "        \n",
    "        # Append the data to a CSV file\n",
    "        if table_data:  # Ensure data is not empty before writing\n",
    "            with open(f\"{stock}.csv\", \"a\", newline=\"\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerows(table_data)\n",
    "    else:\n",
    "        print(f\"Table not found on page {i}\")\n",
    "    \n",
    "    tab1.clickElementWithId(\"myTableCPriceHistory_next\")    \n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the reversing of the data\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(f\"{stock}.csv\")\n",
    "\n",
    "# Reverse the order of rows\n",
    "df = df[::-1].reset_index(drop=True)\n",
    "\n",
    "# Save the modified CSV\n",
    "df.to_csv(f\"sorted_{stock}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove commas from specific column (e.g., 'Price')\n",
    "# df['Open'] = df['Open'].str.replace(',', '').astype(float)\n",
    "# df['High'] = df['High'].str.replace(',', '').astype(float)\n",
    "# df['Low'] = df['Low'].str.replace(',', '').astype(float)\n",
    "# df['Close'] = df['Close'].str.replace(',', '').astype(float)\n",
    "# df['Qty'] = df['Qty'].str.replace(',', '').astype(float)\n",
    "# df['Turnover'] = df['Turnover'].str.replace(',', '').astype(float)\n",
    "\n",
    "# # Save cleaned data back to CSV\n",
    "# df.to_csv(\"cleaned_file.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
